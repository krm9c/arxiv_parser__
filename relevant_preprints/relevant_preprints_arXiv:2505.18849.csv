date,arxiv_num,title,authors,categories,comments,abstract,networked,multi agent reinforcement learning ,sampling,keyword count
arXiv:2505.20090,\\,On Model Predictive Funnel Control with Equilibrium Endpoint Constra=ints,"Jens G\""obel, Dario Dennst\""adt, Lukas Lanza, Karl Worthmann, Thom=as  Berger, Tobias Damm",math.OC,"14 pages, 2 figures ","  We propose model predictive funnel control, a novel model predictive cont= rol (MPC) scheme building upon recent results in funnel control. The latter is a high-gain feedback methodology that achieves evolution of the measured outp= ut within predefined error margins. The proposed method dynamically optimizes a parameter-dependent error boundary in a receding-horizon manner, thereby combining prescribed error guarantees from funnel control with the predicti= ve advantages of MPC. On the one hand, this approach promises faster optimizat= ion times due to a reduced number of decision variables, whose number does not depend on the horizon length. On the other hand, the continuous feedback law improves the robustness and also explicitly takes care of the inter-sampling behavior. We focus on proving stability by leveraging results from MPC stability theory with terminal equality constraints. Moreover, we rigorously show initial and recursive feasibility. ",0.0,0.0,1.0,1
arXiv:2505.18269 (*cross-list,\\,Representative Action Selection for Large Action-Space Meta-Bandits,"Quan Zhou, Mark Kozdoba, Shie Mannor",cs.LG math.OC math.PR stat.ML,0,"  We study the problem of selecting a subset from a large action space shar= ed by a family of bandits, with the goal of achieving performance nearly match= ing that of using the full action space. We assume that similar actions tend to have related payoffs, modeled by a Gaussian process. To exploit this struct= ure, we propose a simple epsilon-net algorithm to select a representative subset= . We provide theoretical guarantees for its performance and compare it empirical= ly to Thompson Sampling and Upper Confidence Bound. ",0.0,0.0,1.0,1
arXiv:2505.18336 (*cross-list,\\,"Sampled-data Systems: Stability, Contractivity and Single-iteration  Suboptimal MPC","Yiting Chen, Francesco Bullo, Emiliano Dall'Anese",eess.SY cs.SY math.OC,0,"  This paper analyzes the stability of interconnected continuous-time (CT) = and discrete-time (DT) systems coupled through sampling and zero-order hold mechanisms. The DT system updates its output at regular intervals $T&gt;0$ = by applying an $n$-fold composition of a given map. This setup is motivated by online and sampled-data implementations of optimization-based controllers - particularly model predictive control (MPC) - where the DT system models $n$ iterations of an algorithm approximating the solution of an optimization problem.   We introduce the concept of a reduced model, defined as the limiting beha= vior of the sampled-data system as $T \to 0^+$ and $n \to +\infty$. Our main theoretical contribution establishes that when the reduced model is contractive, there exists a threshold duration $T(n)$ for each iteration co= unt $n$ such that the CT-DT interconnection achieves exponential stability for = all sampling periods $T &lt; T(n)$. Finally, under the stronger condition that = both the CT and DT systems are contractive, we show exponential stability of the= ir interconnection using a small-gain argument. Our theoretical results provide new insights into suboptimal MPC stability, showing that convergence guaran= tees hold even when using a single iteration of the optimization algorithm - a practically significant finding for real-time control applications. ",0.0,0.0,1.0,1
arXiv:2505.19102 (*cross-list,\\,Statistical inference for Linear Stochastic Approximation with Marko=vian  Noise,"Sergey Samsonov, Marina Sheshukova, Eric Moulines, Alexey Naumov","stat.ML cs.LG math.OC math.ST stat.THMSC-class: 60F05, 62L20, 62E20",0,"  In this paper we derive non-asymptotic Berry-Esseen bounds for Polyak-Rup= pert averaged iterates of the Linear Stochastic Approximation (LSA) algorithm dr= iven by the Markovian noise. Our analysis yields $\mathcal{O}(n^{-1/4})$ converg= ence rates to the Gaussian limit in the Kolmogorov distance. We further establish the non-asymptotic validity of a multiplier block bootstrap procedure for constructing the confidence intervals, guaranteeing consistent inference un= der Markovian sampling. Our work provides the first non-asymptotic guarantees on the rate of convergence of bootstrap-based confidence intervals for stochas= tic approximation with Markov noise. Moreover, we recover the classical rate of order $\mathcal{O}(n^{-1/8})$ up to logarithmic factors for estimating the asymptotic variance of the iterates of the LSA algorithm. ",0.0,0.0,1.0,1
