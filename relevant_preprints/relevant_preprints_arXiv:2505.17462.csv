date,arxiv_num,title,authors,categories,comments,abstract,networked,multi agent reinforcement learning ,sampling,keyword count
arXiv:2505.17283 (*cross-list,\\,Deconfounded Warm-Start Thompson Sampling with Applications to Preci=sion  Medicine,"Prateek Jaiswal, Esmaeil Keyvanshokooh, Junyu Cao",stat.ML cs.LG math.OC stat.AP,0,"  Randomized clinical trials often require large patient cohorts before dra= wing definitive conclusions, yet abundant observational data from parallel studi= es remains underutilized due to confounding and hidden biases. To bridge this = gap, we propose Deconfounded Warm-Start Thompson Sampling (DWTS), a practical approach that leverages a Doubly Debiased LASSO (DDL) procedure to identify=  a sparse set of reliable measured covariates and combines them with key hidden covariates to form a reduced context. By initializing Thompson Sampling (Li= nTS) priors with DDL-estimated means and variances on these measured features -- while keeping uninformative priors on hidden features -- DWTS effectively harnesses confounded observational data to kick-start adaptive clinical tri= als. Evaluated on both a purely synthetic environment and a virtual environment created using real cardiovascular risk dataset, DWTS consistently achieves lower cumulative regret than standard LinTS, showing how offline causal insights from observational data can improve trial efficiency and support m= ore personalized treatment decisions. ",0.0,0.0,2.0,1
arXiv:2505.17469 (*cross-list,\\,Efficient compression of neural networks and datasets,"Lukas Silvester Barth, Paulo von Petersenn",cs.LG cs.AI cs.IT math.IT math.OC math.ST stat.TH,"10 pages plus appendix, 9 Figures, 3 Tables MSC-class: 94-08, 94-04, 68T07, 68T50 ACM-class: E.4; H.1.1; I.2; I.2.6; I.2.7 ","  We compare, improve, and contribute methods that substantially decrease t= he number of parameters of neural networks while maintaining high test accurac= y. When applying our methods to minimize description length, we obtain very effective data compression algorithms. In particular, we develop a probabilistic reformulation of $\ell_0$ regularized optimization for nonlin= ear models that does not require Monte-Carlo sampling and thus improves upon previous methods. We also improve upon methods involving smooth approximati= ons to the $\ell_0$ norm, and investigate layerwise methods. We compare the met= hods on different architectures and datasets, including convolutional networks trained on image datasets and transformers trained on parts of Wikipedia. We also created a synthetic teacher-student setup to investigate compression i= n a controlled continuous setting. Finally, we conceptually relate compression algorithms to Solomonoff's theory of inductive inference and empirically ve= rify the prediction that regularized models can exhibit more sample-efficient convergence. ",0.0,0.0,1.0,1
arXiv:2505.17857 (*cross-list,\\,Sufficient Conditions for Detectability of Approximately Discretized  Nonlinear Systems,"Seth Siriya, Julian D. Schiller, Victor G. Lopez, Matthias A. M\""u=ller",eess.SY cs.SY math.OC,"7 pages, submitted to 23rd European Control Conference ","  In many sampled-data applications, observers are designed based on approximately discretized models of continuous-time systems, where usually = only the discretized system is analyzed in terms of its detectability. In this paper, we show that if the continuous-time system satisfies certain linear matrix inequality (LMI) conditions, and the sampling period of the discretization scheme is sufficiently small, then the whole family of discretized systems (parameterized by the sampling period) satisfies analog= ous discrete-time LMI conditions that imply detectability. Our results are applicable to general discretization schemes, as long as they produce approximate models whose linearizations are in some sense consistent with t= he linearizations of the continuous-time ones. We explicitly show that the Eul= er and second-order Runge-Kutta methods satisfy this condition. A batch-reactor system example is provided to highlight the usefulness of our results from a practical perspective. ",0.0,0.0,1.0,1
