date,arxiv_num,title,authors,categories,comments,abstract,networked,multi agent reinforcement learning ,sampling,keyword count
arXiv:2505.04820 (*cross-list,\\,Convergent Complex Quasi-Newton Proximal Methods for Gradient-Driven  Denoisers in Compressed Sensing MRI Reconstruction,"Tao Hong, Zhaoyi Xu, Se Young Chun, Luis Hernandez-Garcia, and Jef=frey  A. Fessler",eess.IV cs.NA math.NA math.OC,"12 pages, 10 figures,   <a href=3D""https://urldefense.us/v3/__https://hongtao-argmin.github.io/CQ= NPM-GD-CSMRI/__;!!G_uCfscf7eWS!c79AzOOGdylbR6gLQHx__84hgm2Ua1pvSnK5ovsKY5pM= OVHjIAGuWeN24q1tubUpXHIt4sYAh3GPzyAwxEE$"">https://urldefense.us/v3/__https:= //hongtao-argmin.github.io/CQNPM-GD-CSMRI/__;!!G_uCfscf7eWS!c79AzOOGdylbR6g= LQHx__84hgm2Ua1pvSnK5ovsKY5pMOVHjIAGuWeN24q1tubUpXHIt4sYAh3GPzyAwxEE$</a> ","  In compressed sensing (CS) MRI, model-based methods are pivotal to achiev= ing accurate reconstruction. One of the main challenges in model-based methods = is finding an effective prior to describe the statistical distribution of the target image. Plug-and-Play (PnP) and REgularization by Denoising (RED) are=  two general frameworks that use denoisers as the prior. While PnP/RED methods w= ith convolutional neural networks (CNNs) based denoisers outperform classical hand-crafted priors in CS MRI, their convergence theory relies on assumptio= ns that do not hold for practical CNNs. The recently developed gradient-driven denoisers offer a framework that bridges the gap between practical performa= nce and theoretical guarantees. However, the numerical solvers for the associat= ed minimization problem remain slow for CS MRI reconstruction. This paper prop= oses a complex quasi-Newton proximal method that achieves faster convergence than existing approaches. To address the complex domain in CS MRI, we propose a modified Hessian estimation method that guarantees Hermitian positive definiteness. Furthermore, we provide a rigorous convergence analysis of the proposed method for nonconvex settings. Numerical experiments on both Carte= sian and non-Cartesian sampling trajectories demonstrate the effectiveness and efficiency of our approach. ",0.0,0.0,1.0,1
arXiv:2505.05301 (*cross-list,\\,Operator-Level Quantum Acceleration of Non-Logconcave Sampling,"Jiaqi Leng, Zhiyan Ding, Zherui Chen, Lin Lin",quant-ph cs.LG math.OC,"43 pages, 7 figures ","  Sampling from probability distributions of the form $\sigma \propto e^{-\= beta V}$, where $V$ is a continuous potential, is a fundamental task across phys= ics, chemistry, biology, computer science, and statistics. However, when $V$ is non-convex, the resulting distribution becomes non-logconcave, and classical methods such as Langevin dynamics often exhibit poor performance. We introd= uce the first quantum algorithm that provably accelerates a broad class of continuous-time sampling dynamics. For Langevin dynamics, our method encodes the target Gibbs measure into the amplitudes of a quantum state, identified=  as the kernel of a block matrix derived from a factorization of the Witten Laplacian operator. This connection enables Gibbs sampling via singular val= ue thresholding and yields the first provable quantum advantage with respect to the Poincar\'e constant in the non-logconcave setting. Building on this framework, we further develop the first quantum algorithm that accelerates replica exchange Langevin diffusion, a widely used method for sampling from complex, rugged energy landscapes. ",0.0,0.0,2.0,1
