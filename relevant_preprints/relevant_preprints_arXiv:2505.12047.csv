date,arxiv_num,title,authors,categories,comments,abstract,networked,multi agent reinforcement learning ,sampling,keyword count
arXiv:2505.11518,\\,Deep Unrolled Meta-Learning for Multi-Coil and Multi-Modality MRI wi=th  Adaptive Optimization,"Merham Fouladvand, Peuroly Batra",math.OC cs.CV,0,"  We propose a unified deep meta-learning framework for accelerated magnetic resonance imaging (MRI) that jointly addresses multi-coil reconstruction and cross-modality synthesis. Motivated by the limitations of conventional meth= ods in handling undersampled data and missing modalities, our approach unrolls a provably convergent optimization algorithm into a structured neural network architecture. Each phase of the network mimics a step of an adaptive forward-backward scheme with extrapolation, enabling the model to incorpora= te both data fidelity and nonconvex regularization in a principled manner. To enhance generalization across different acquisition settings, we integrate meta-learning, which enables the model to rapidly adapt to unseen sampling patterns and modality combinations using task-specific meta-knowledge. The proposed method is evaluated on the open source datasets, showing significa= nt improvements in PSNR and SSIM over conventional supervised learning, especi= ally under aggressive undersampling and domain shifts. Our results demonstrate t= he synergy of unrolled optimization, task-aware meta-learning, and modality fusion, offering a scalable and generalizable solution for real-world clini= cal MRI reconstruction. ",0.0,0.0,1.0,1
arXiv:2505.12378,\\,Efficient Optimization with Orthogonality Constraint: a Randomized  Riemannian Submanifold Method,"Andi Han, Pierre-Louis Poirion, Akiko Takeda",math.OC cs.LG stat.ML,Accepted to ICML 2025 ,"  Optimization with orthogonality constraints frequently arises in various fields such as machine learning. Riemannian optimization offers a powerful framework for solving these problems by equipping the constraint set with a Riemannian manifold structure and performing optimization intrinsically on = the manifold. This approach typically involves computing a search direction in = the tangent space and updating variables via a retraction operation. However, as the size of the variables increases, the computational cost of the retracti= on can become prohibitively high, limiting the applicability of Riemannian optimization to large-scale problems. To address this challenge and enhance scalability, we propose a novel approach that restricts each update on a ra= ndom submanifold, thereby significantly reducing the per-iteration complexity. We introduce two sampling strategies for selecting the random submanifolds and theoretically analyze the convergence of the proposed methods. We provide convergence results for general nonconvex functions and functions that sati= sfy Riemannian Polyak-Lojasiewicz condition as well as for stochastic optimizat= ion settings. Additionally, we demonstrate how our approach can be generalized = to quotient manifolds derived from the orthogonal manifold. Extensive experime= nts verify the benefits of the proposed method, across a wide variety of proble= ms. ",0.0,0.0,1.0,1
arXiv:2505.12383,\\,High-dimensional Optimization with Low Rank Tensor Sampling and Local  Search,"Konstantin Sozykin, Andrei Chertkov, Anh-Huy Phan, Ivan Oseledets,  Gleb Ryzhakov",math.OC cs.NA math.NA,0,"  We present a novel method called TESALOCS (TEnsor SAmpling and LOCal Sear= ch) for multidimensional optimization, combining the strengths of gradient-free discrete methods and gradient-based approaches. The discrete optimization in our method is based on low-rank tensor techniques, which, thanks to their low-parameter representation, enable efficient optimization of high-dimensi= onal problems. For the second part, i.e., local search, any effective gradient-b= ased method can be used, whether existing (such as quasi-Newton methods) or any other developed in the future. Our approach addresses the limitations of gradient-based methods, such as getting stuck in local optima; the limitati= ons of discrete methods, which cannot be directly applied to continuous functio= ns; and limitations of gradient-free methods that require large computational budgets. Note that we are not limited to a single type of low-rank tensor decomposition for discrete optimization, but for illustrative purposes, we consider a specific efficient low-rank tensor train decomposition. For 20 challenging 100-dimensional functions, we demonstrate that our method can significantly outperform results obtained with gradient-based methods like Conjugate Gradient, BFGS, SLSQP, and other methods, improving them by order= s of magnitude with the same computing budget. ",0.0,0.0,2.0,1
arXiv:2505.12409,\\,The Stochastic Multi-Proximal Method for Nonsmooth Optimization,"Laurent Condat, Elnur Gasanov, Peter Richt\'arik",math.OC,0,"  Stochastic gradient descent type methods are ubiquitous in machine learni= ng, but they are only applicable to the optimization of differentiable function= s. Proximal algorithms are more general and applicable to nonsmooth functions.=  We propose a new stochastic and variance-reduced algorithm, the Stochastic Multi-Proximal Method (SMPM), in which the proximity operators of a (possib= ly empty) random subset of functions are called at every iteration, according = to an arbitrary sampling distribution. Several existing algorithms, including Point-SAGA (2016), Proxskip (2022) and RandProx-Minibatch (2023) are recove= red as particular cases. We derive linear convergence results in presence of st= rong convexity and smoothness or similarity of the functions. We prove convergen= ce in the general convex case and accelerated O(1/t2) convergence with varying stepsizes in presence of strong convexity solely. Our results are new even = for the above special cases. Moreover, we show an application to distributed optimization with compressed communication, outperforming existing methods. ",0.0,0.0,1.0,1
arXiv:2505.12553,\\,Hamiltonian Descent Algorithms for Optimization: Accelerated Rates v=ia  Randomized Integration Time,"Qiang Fu, Andre Wibisono",math.OC cs.LG stat.ML,0,"  We study the Hamiltonian flow for optimization (HF-opt), which simulates = the Hamiltonian dynamics for some integration time and resets the velocity to $= 0$ to decrease the objective function; this is the optimization analogue of the Hamiltonian Monte Carlo algorithm for sampling. For short integration time, HF-opt has the same convergence rates as gradient descent for minimizing strongly and weakly convex functions. We show that by randomizing the integration time in HF-opt, the resulting randomized Hamiltonian flow (RHF) achieves accelerated convergence rates in continuous time, similar to the r= ates for the accelerated gradient flow. We study a discrete-time implementation = of RHF as the randomized Hamiltonian gradient descent (RHGD) algorithm. We pro= ve that RHGD achieves the same accelerated convergence rates as Nesterov's accelerated gradient descent (AGD) for minimizing smooth strongly and weakly convex functions. We provide numerical experiments to demonstrate that RHGD=  is competitive with classical accelerated methods such as AGD across all setti= ngs and outperforms them in certain regimes. ",0.0,0.0,1.0,1
arXiv:2505.12599,\\,Accelerated Markov Chain Monte Carlo Algorithms on Discrete States,"Bohan Zhou, Shu Liu, Xinzhe Zuo, Wuchen Li","math.OC cs.LG stat.COMSC-class: 65C05, 60J22, 82M31, 49Q22, 65K10",0,"  We propose a class of discrete state sampling algorithms based on Nestero= v's accelerated gradient method, which extends the classical Metropolis-Hastings (MH) algorithm. The evolution of the discrete states probability distributi= on governed by MH can be interpreted as a gradient descent direction of the Kullback--Leibler (KL) divergence, via a mobility function and a score function. Specifically, this gradient is defined on a probability simplex equipped with a discrete Wasserstein-2 metric with a mobility function. This motivates us to study a momentum-based acceleration framework using damped Hamiltonian flows on the simplex set, whose stationary distribution matches=  the discrete target distribution. Furthermore, we design an interacting particle system to approximate the proposed accelerated sampling dynamics. The exten= sion of the algorithm with a general choice of potentials and mobilities is also discussed. In particular, we choose the accelerated gradient flow of the relative Fisher information, demonstrating the advantages of the algorithm = in estimating discrete score functions without requiring the normalizing const= ant and keeping positive probabilities. Numerical examples, including sampling = on a Gaussian mixture supported on lattices or a distribution on a hypercube, demonstrate the effectiveness of the proposed discrete-state sampling algorithm. ",0.0,0.0,1.0,1
